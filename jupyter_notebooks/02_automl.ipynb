{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with AutoML\n",
    "Explore different AutoML libraries for Scikit-Learn to see whether this can improve our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents\n",
    "* [Data loading, performance metric & preprocessing](#loaddata)\n",
    "* [AutoML libraries](#automl)\n",
    "    * [TPOT](#tpot)\n",
    "    * [Auto-Sklearn](#autosklearn)\n",
    "    * [HyperOpt](#hyperopt)\n",
    "* [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import make_scorer, mean_squared_log_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from tpot import TPOTRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "train_data_file = \"../data/train.csv\"\n",
    "test_data_file = \"../data/test.csv\"\n",
    "tpot_predictions_file = \"../results/02_predictions_tpot.csv\"\n",
    "SEED = 0\n",
    "CV = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading, performance metric & preprocessing <a class=\"anchor\"  id=\"loaddata\"></a>\n",
    "The code for loading the data, defining the performance metric and a basic preprocessing is copied from [01_basic.ipynb](jupyter_notebooks/01_basic.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_df = pd.read_csv(train_data_file)\n",
    "train_df.set_index(\"Id\", inplace=True)\n",
    "target_col = \"SalePrice\"\n",
    "y_train = train_df[target_col]\n",
    "X_train = train_df.drop(columns=[target_col])\n",
    "cat_cols = X_train.select_dtypes(include=[\"object\"]).columns\n",
    "num_cols = X_train.select_dtypes(exclude=[\"object\"]).columns\n",
    "\n",
    "X_test = pd.read_csv(test_data_file)\n",
    "X_test.set_index(\"Id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define performance metric\n",
    "neg_RMSLE_scorer = make_scorer(\n",
    "    mean_squared_log_error, greater_is_better=False, squared=False\n",
    ")\n",
    "\n",
    "\n",
    "def measure_performance(estimator, X, y, scorer=neg_RMSLE_scorer, cv=CV):\n",
    "    \"\"\"Calculate negative RMSLE for train and test set via cross validation.\"\"\"\n",
    "    cv_results = cross_validate(\n",
    "        estimator=estimator,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        cv=cv,\n",
    "        scoring=scorer,\n",
    "        return_train_score=True,\n",
    "    )\n",
    "    test_error = cv_results[\"test_score\"].mean()\n",
    "    train_error = cv_results[\"train_score\"].mean()\n",
    "    return train_error, test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic preprocessing\n",
    "simple_imputer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"num_imputer\",\n",
    "            SimpleImputer(strategy=\"mean\", keep_empty_features=True),\n",
    "            num_cols,\n",
    "        ),\n",
    "        (\n",
    "            \"cat_imputer\",\n",
    "            SimpleImputer(strategy=\"most_frequent\", keep_empty_features=True),\n",
    "            cat_cols,\n",
    "        ),\n",
    "    ],\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "simple_imputer.set_output(transform=\"pandas\")\n",
    "\n",
    "ordinal_encoder = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"ordinal_encoder\",\n",
    "            OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n",
    "            cat_cols,\n",
    "        )\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "ordinal_encoder.set_output(transform=\"pandas\")\n",
    "\n",
    "preprocessing = Pipeline(\n",
    "    steps=[(\"imputer\", simple_imputer), (\"encoder\", ordinal_encoder)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML libraries <a class=\"anchor\"  id=\"automl\"></a>\n",
    "AutoML stands for Automated Machine Learning. It is a tool to automatically obtain a machine learning pipeline with a relatively good performance. This is achieved via an optimization of the model selection, hyperparameter tuning and some data preprocessing. There are different applied techniques for optimzation like grid or random search, Bayesian optimization or evolutionary algorithms.\n",
    "\n",
    "\n",
    "We will test and compare multiple AutoML libraries for scikit-learn: TPOT, Auto-Sklearn and HyperOpt-Sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPOT <a class=\"anchor\"  id=\"tpot\"></a>\n",
    "TPOT stands for tree based pipeline optimization tool. it uses genetic programming (evolutionary algotihm) for optimization.\n",
    "\n",
    "The input data must be numerical only. Therefore before running TPOT, missing values are handled and categorical features are encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                             \n",
      "Generation 1 - Current best internal CV score: -0.13356697090230968\n",
      "                                                                              \n",
      "Generation 2 - Current best internal CV score: -0.13356697090230968\n",
      "                                                                              \n",
      "Generation 3 - Current best internal CV score: -0.1332053119755611\n",
      "                                                                              \n",
      "Generation 4 - Current best internal CV score: -0.13114245280134335\n",
      "                                                                              \n",
      "Generation 5 - Current best internal CV score: -0.13114245280134335\n",
      "                                                                              \n",
      "Best pipeline: XGBRegressor(input_matrix, learning_rate=0.1, max_depth=6, min_child_weight=18, n_estimators=100, n_jobs=1, objective=reg:squarederror, subsample=0.55, verbosity=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;xgbregressor&#x27;,\n",
       "                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                              colsample_bylevel=None, colsample_bynode=None,\n",
       "                              colsample_bytree=None, early_stopping_rounds=None,\n",
       "                              enable_categorical=False, eval_metric=None,\n",
       "                              feature_types=None, gamma=None, gpu_id=None,\n",
       "                              grow_policy=None, importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=0.1,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=6, max_leaves=None, min_child_weight=18,\n",
       "                              missing=nan, monotone_constraints=None,\n",
       "                              n_estimators=100, n_jobs=1,\n",
       "                              num_parallel_tree=None, predictor=None,\n",
       "                              random_state=0, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;xgbregressor&#x27;,\n",
       "                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                              colsample_bylevel=None, colsample_bynode=None,\n",
       "                              colsample_bytree=None, early_stopping_rounds=None,\n",
       "                              enable_categorical=False, eval_metric=None,\n",
       "                              feature_types=None, gamma=None, gpu_id=None,\n",
       "                              grow_policy=None, importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=0.1,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=6, max_leaves=None, min_child_weight=18,\n",
       "                              missing=nan, monotone_constraints=None,\n",
       "                              n_estimators=100, n_jobs=1,\n",
       "                              num_parallel_tree=None, predictor=None,\n",
       "                              random_state=0, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "             min_child_weight=18, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=1, num_parallel_tree=None, predictor=None,\n",
       "             random_state=0, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('xgbregressor',\n",
       "                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                              colsample_bylevel=None, colsample_bynode=None,\n",
       "                              colsample_bytree=None, early_stopping_rounds=None,\n",
       "                              enable_categorical=False, eval_metric=None,\n",
       "                              feature_types=None, gamma=None, gpu_id=None,\n",
       "                              grow_policy=None, importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=0.1,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=6, max_leaves=None, min_child_weight=18,\n",
       "                              missing=nan, monotone_constraints=None,\n",
       "                              n_estimators=100, n_jobs=1,\n",
       "                              num_parallel_tree=None, predictor=None,\n",
       "                              random_state=0, ...))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run TPOT:\n",
    "tpot = TPOTRegressor(\n",
    "    generations=5,\n",
    "    population_size=50,\n",
    "    cv=CV,\n",
    "    scoring=neg_RMSLE_scorer,\n",
    "    early_stop=3,\n",
    "    verbosity=2,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "X_train_processed = preprocessing.fit_transform(X_train)\n",
    "tpot.fit(X_train_processed, y_train)\n",
    "tpot_best_model = tpot.fitted_pipeline_\n",
    "tpot_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: -0.08749420601136189; Test error: -0.13114245280134335\n"
     ]
    }
   ],
   "source": [
    "# measure performance:\n",
    "train_error, test_error = measure_performance(\n",
    "    tpot_best_model, X_train_processed, y_train\n",
    ")\n",
    "print(f\"Train error: {train_error}; Test error: {test_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>125455.976562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>160246.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>181554.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>183471.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>192670.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  125455.976562\n",
       "1  1462  160246.015625\n",
       "2  1463  181554.750000\n",
       "3  1464  183471.781250\n",
       "4  1465  192670.500000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make test predictions:\n",
    "X_test_processed = preprocessing.transform(X_test)\n",
    "tpot_best_model.fit(X=X_train_processed, y=y_train)\n",
    "pred_test = tpot_best_model.predict(X=X_test_processed)\n",
    "prediction_df = pd.DataFrame({\"Id\": X_test.index, \"SalePrice\": pred_test})\n",
    "prediction_df.to_csv(tpot_predictions_file, index=False)\n",
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-Sklearn <a class=\"anchor\"  id=\"autosklearn\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperopt <a class=\"anchor\"  id=\"hyperopt\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion <a class=\"anchor\"  id=\"conclusion\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
